---
title: "为什么很多编程语言数组下标从0开始"
date: 2021-05-12T21:33:44+08:00
draft: true
tags:
 - 算法
 - 数组
---

## 数组
> 数组（Array）是一种**线性表数据结构**。它用一组**连续的内存空间**，来存储一组具有**相同类型的数据**。

### 1. 线性表(Linear List)
线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。
- 其实除了`数组`，`链表、队列、栈`等也是线性表结构。

![](https://static001.geekbang.org/resource/image/b6/77/b6b71ec46935130dff5c4b62cf273477.jpg#w60)

**非线性表**

`二叉树`、`堆`、`图`等。之所以叫非线性，是因为，`在非线性表中，数据之间并不是简单的前后关系`。

![](https://static001.geekbang.org/resource/image/6e/69/6ebf42641b5f98f912d36f6bf86f6569.jpg#w60)

### 2. 连续的内存空间和相同类型的数据
- 正因为这两个限制，它才有了一个堪称“杀手锏”的特性：`随机访问`。

- 但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如要想在数组中`删除、插入`一个数据，为了保证连续性，就需要做大量的数据搬移工作。

## 数组是如何实现根据下标随机访问数组元素的？
拿长度为10的int类型数组 `int[] a = new int[10]` 举例, 计算机给数组 a[10]，分配了一块连续内存空间 1000～1039，其中，内存块的首地址为 base_address = 1000。

![](https://static001.geekbang.org/resource/image/98/c4/98df8e702b14096e7ee4a5141260cdc4.jpg#w60)

我们知道, 计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。

当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址
```
a[i]_address = base_address + i * data_type_size
```
- data_type_size 表示数组中每个元素的大小,这个例子中,数组中存储的是 int 类型数据，所以 data_type_size 就为 4 个字节
- base-address  当前例子 1000

## 数组和链表的区别
- 表述不准确: `“链表适合插入、删除，时间复杂度 O(1)；数组适合查找，查找时间复杂度为 O(1)"`

数组是适合查找操作，但是查找的时间复杂度并不为 O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是 O(logn)

- 正确表述: `数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)`

## 低效的插入和删除
### 数组的插入

- 在数组开头插入元素,那所有的数据都需要依次往后移动一位,最坏时间复杂度 O(n)
- 数组末尾插入元素,不需要移动数据 O(1)
- 因为我们在每个位置插入元素的概率是一样的，所以`平均情况时间复杂度`为 (1+2+...n)/n=`O(n)`。

### 无序数组的插入
- 如果数组中的数据是有序的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法搬移 k 之后的数据,
- 如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。

![](https://static001.geekbang.org/resource/image/3f/dc/3f70b4ad9069ec568a2caaddc231b7dc.jpg#w60)

`在特定场景下，在第 k 个位置插入一个元素的时间复杂度就会降为 O(1)`。这个处理思想在快排中也会用到

### 删除操作
和插入类似,如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为 O(n)。

在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们`将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢`？

例如:数组 a[10]中存储了 8 个元素：a，b，c，d，e，f，g，h。现在，我们要依次删除 a，b，c 三个元素。

![](https://static001.geekbang.org/resource/image/b6/e5/b69b8c5dbf6248649ddab7d3e7cfd7e5.jpg#w60)

为了避免 d，e，f，g，h 这几个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。

如果你了解 JVM，你会发现，这不就是 `JVM 标记清除垃圾回收算法的核心思想`吗？没错，数据结构和算法的魅力就在于此，`很多时候我们并不是要去死记硬背某个数据结构或者算法，而是要学习它背后的思想和处理技巧，这些东西才是最有价值的`。

## 警惕数组的访问越界问题

```c
int main(int argc, char* argv[]){
    int i = 0;
    int arr[3] = {0};
    for(; i<=3; i++){
        arr[i] = 0;
        printf("hello world\n");
    }
    return 0;
}
```
你发现问题了吗？这段代码的运行结果并非是打印三行“hello word”，而是会无限打印“hello world”，这是为什么呢？

因为，`数组大小为 3，a[0]，a[1]，a[2]，而我们的代码因为书写错误，导致 for 循环的结束条件错写为了 i<=3 而非 i<3，所以当 i=3 时，数组 a[3]访问越界`。

在 C 语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。根据我们前面讲的数组寻址公式，`a[3]也会被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量 i 的内存地址，那么 a[3]=0 就相当于 i=0，所以就会导致代码无限循环`。

数组越界在 C 语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。因为，`访问数组的本质就是访问一段连续内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误`。

## 容器能否完全替代数组？
针对数组类型，很多语言都提供了容器类，比如 Java 中的 `ArrayList`、C++ STL 中的 `vector`。

拿 Java 语言来举例。如果你是 Java 工程师，几乎天天都在用 ArrayList, 那它与数组相比，到底有哪些优势呢？

ArrayList 最大的优势就是`可以将很多数组操作的细节封装起来`。比如前面提到的数组插入、删除数据时需要搬移其他数据等。另外，它还有一个优势，就是`支持动态扩容`。

数组本身在定义的时候需要预先指定大小，因为需要分配连续的内存空间。如果我们申请了大小为 10 的数组，当第 11 个数据需要存储到数组中时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后再将新的数据插入。

如果使用 ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList 已经帮我们实现好了。每次存储空间不够的时候，它都会将空间`自动扩容为 1.5 倍`大小。

因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，最好在创建 ArrayList 的时候事先指定数据大小。

## 解答开篇
为什么大多数编程语言中，数组要从 0 开始编号，而不是从 1 开始呢？

### 减少一次减法指令
从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。前面也讲到，如果用 a 来表示数组的首地址，a[0]就是偏移为 0 的位置，也就是首地址，a[k]就表示偏移 k 个 type_size 的位置，所以计算 a[k]的内存地址只需要用这个公式：

```
a[k]_address = base_address + k * type_size
```

但是，如果数组从 1 开始计数，那我们计算数组元素 a[k]的内存地址就会变为：
```
a[k]_address = base_address + (k-1)*type_size
```

对比两个公式，我们不难发现，`从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令`。

数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。

### 历史原因
C 语言设计者用 0 开始计数数组下标，之后的 Java、JavaScript 等高级语言都效仿了 C 语言，或者说，为了在一定程度上减少 C 语言程序员学习 Java 的学习成本，因此继续沿用了从 0 开始计数的习惯。实际上，很多语言中数组也并不是从 0 开始计数的，比如 Matlab。甚至还有一些语言支持负数下标，比如 Python。

## 总结
> 数组用一块连续的内存空间，来存储相同类型的一组数据，最大的特点就是支持随机访问，但插入、删除操作也因此变得比较低效，平均情况时间复杂度为 O(n)。

## PS
### JVM标记清楚算法

大多数主流虚拟机采用可达性分析算法来判断对象是否存活，在标记阶段，会遍历所有 GC ROOTS，将所有 GC ROOTS 可达的对象标记为存活。只有当标记工作完成后，清理工作才会开始。

不足：
- 1.效率问题。标记和清理效率都不高，但是当知道只有少量垃圾产生时会很高效。
- 2.空间问题。会产生不连续的内存空间碎片。

### 二维数组内存寻址：

对于 m * n 的数组，a [ i ][ j ] (i < m,j < n)的地址为：

```
address = base_address + ( i * n + j) * type_size
```